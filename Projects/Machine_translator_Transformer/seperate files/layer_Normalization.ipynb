{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization2(nn.Module):\n",
    "\n",
    "    def __init__(self, features: int, eps:float=10**-6) -> None:\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.alpha = nn.Parameter(torch.ones(features)) # alpha is a learnable parameter\n",
    "        self.bias = nn.Parameter(torch.zeros(features)) # bias is a learnable parameter\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len, hidden_size)\n",
    "         # Keep the dimension for broadcasting\n",
    "        mean = x.mean(dim = -1, keepdim = True) # (batch, seq_len, 1)\n",
    "        # Keep the dimension for broadcasting\n",
    "        std = x.std(dim = -1, keepdim = True) # (batch, seq_len, 1)\n",
    "        # eps is to prevent dividing by zero or when std is very small\n",
    "        return self.alpha * (x - mean) / (std + self.eps) + self.bias\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(nn.Module):\n",
    "    def __init__(self, parameters_shape, eps = 1e-5):\n",
    "        super().__init__()\n",
    "        self.parameter_shape = parameters_shape\n",
    "        self.eps = eps\n",
    "        self.gamma = nn.Parameter(torch.ones(parameters_shape))\n",
    "        self.beta = nn.Parameter(torch.zeros(parameters_shape))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        dims = [-(i+1) for i in range(len(self.parameter_shape))]\n",
    "\n",
    "        mean = inputs.mean(dim = dims, keepdim = True)\n",
    "        print(f\"Mean ({mean.size()})\")\n",
    "\n",
    "        var = ((inputs-mean)**2).mean(dim = dims,keepdim = True)\n",
    "\n",
    "        std = (var + self.eps).sqrt()\n",
    "        print(f\"Standard Deviation  ({std.size()})\")\n",
    "\n",
    "        y = (inputs - mean) / std\n",
    "        print(f\"y: {y.size()}\")\n",
    "\n",
    "        out = self.gamma * y + self.beta\n",
    "        print(f\"self.gamma: {self.gamma.size()}, self.beta: {self.beta.size()}\")\n",
    "        \n",
    "        print(f\"out: {out.size()}\")\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "sentence_length = 5\n",
    "embedding_dim = 8\n",
    "inputs = torch.randn(sentence_length, batch_size, embedding_dim)\n",
    "print(inputs.shape)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.Tensor([[[0.2,0.1,0.3],[0.5,0.1,0.1]]])\n",
    "B, S, E = inputs.size()\n",
    "inputs = inputs.reshape(S, B,E)\n",
    "inputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3]), torch.Size([1, 3]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_shape = inputs.size()[-2:]\n",
    "gamma = nn.Parameter(torch.ones(parameter_shape))\n",
    "beta = nn.Parameter(torch.zeros(parameter_shape))\n",
    "print(parameter_shape)\n",
    "gamma.size(), beta.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, -2]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims = [-(i+1) for i in range(len(parameter_shape))]\n",
    "dims # batch and embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = inputs.mean(dim = dims ,keepdim=True)\n",
    "mean.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0817]],\n",
       "\n",
       "        [[0.1886]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = ((inputs - mean)**2).mean(dim = dims, keepdim=True)\n",
    "epsilon = 1e-5\n",
    "std = (var + epsilon).sqrt()\n",
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000, -1.2238,  1.2238]],\n",
       "\n",
       "        [[ 1.4140, -0.7070, -0.7070]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = (inputs - mean) / std\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000, -1.2238,  1.2238]],\n",
       "\n",
       "        [[ 1.4140, -0.7070, -0.7070]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = gamma * y + beta\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(nn.Module):\n",
    "    def __init__(self, parameter_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.parameter_shape = parameter_shape\n",
    "        self.eps = eps\n",
    "        self.gamma = nn.Parameter(torch.ones(parameter_shape))\n",
    "        self.beta = nn.Parameter(torch.zeros(parameter_shape))\n",
    "\n",
    "    def forward(self, x):\n",
    "        dims = [-(i+1)for i in range(len(self.parameter_shape))]\n",
    "        print(f\"Dimensions: {dims}\")\n",
    "\n",
    "        mean = x.mean(dim = dims , keepdim = True)\n",
    "        print(f\"Mean: {mean}\")\n",
    "\n",
    "        var = ((x - mean)**2).mean(dim = dims, keepdim = True) \n",
    "        print(f\"Variance: {var}\")\n",
    "\n",
    "        std = (var + self.eps).sqrt()\n",
    "        print(f\"Standard Deviation: {std}\")\n",
    "\n",
    "        y = (x - mean) / std\n",
    "        print(f\"y: {y}\") \n",
    "\n",
    "        out = self.gamma * y + self.beta\n",
    "        print(f\"out: {out}\")\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "sentence_length = 2\n",
    "embedding_dim =  3 \n",
    "inputs = torch.Tensor([[[0.2,0.1,0.3],[0.5,0.1,0.1]]])\n",
    "inputs = inputs.reshape(sentence_length, batch_size, embedding_dim)\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization2(nn.Module):\n",
    "\n",
    "    def __init__(self, features: int, eps:float=10**-6) -> None:\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.alpha = nn.Parameter(torch.ones(features)) # alpha is a learnable parameter\n",
    "        self.bias = nn.Parameter(torch.zeros(features)) # bias is a learnable parameter\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len, hidden_size)\n",
    "         # Keep the dimension for broadcasting\n",
    "        mean = x.mean(dim = -1, keepdim = True) # (batch, seq_len, 1)\n",
    "        print(f\"Mean: {mean}\")\n",
    "        # Keep the dimension for broadcasting\n",
    "        std = x.std(dim = -1, keepdim = True) # (batch, seq_len, 1)\n",
    "        print(f\"Standard Deviation: {std}\")\n",
    "        # eps is to prevent dividing by zero or when std is very small\n",
    "        out = self.alpha * (x - mean) / (std + self.eps) + self.bias\n",
    "        print(f\"out: {out}\")\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: [-1, -2]\n",
      "Mean: tensor([[[0.2000]],\n",
      "\n",
      "        [[0.2333]]])\n",
      "Variance: tensor([[[0.0067]],\n",
      "\n",
      "        [[0.0356]]])\n",
      "Standard Deviation: tensor([[[0.0817]],\n",
      "\n",
      "        [[0.1886]]])\n",
      "y: tensor([[[ 0.0000, -1.2238,  1.2238]],\n",
      "\n",
      "        [[ 1.4140, -0.7070, -0.7070]]])\n",
      "out: tensor([[[ 0.0000, -1.2238,  1.2238]],\n",
      "\n",
      "        [[ 1.4140, -0.7070, -0.7070]]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 3])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln = LayerNormalization(inputs.size()[-2:])\n",
    "out = ln(inputs)\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 3])\n",
      "Mean: tensor([[[0.2000]],\n",
      "\n",
      "        [[0.2333]]])\n",
      "Standard Deviation: tensor([[[0.1000]],\n",
      "\n",
      "        [[0.2309]]])\n",
      "out: tensor([[[ 0.0000, -1.0000,  1.0000]],\n",
      "\n",
      "        [[ 1.1547, -0.5773, -0.5773]]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 3])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 1\n",
    "sentence_length = 2\n",
    "embedding_dim =  3 \n",
    "inputs = torch.Tensor([[[0.2,0.1,0.3],[0.5,0.1,0.1]]])\n",
    "inputs = inputs.reshape(sentence_length, batch_size, embedding_dim)\n",
    "print(inputs.shape)\n",
    "ln = LayerNormalization2(inputs.size()[-1])\n",
    "ln.forward(inputs).size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
