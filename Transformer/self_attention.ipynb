{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, d_k, d_v = 4, 8, 8   # L-> size of input and d_v and d_k is length of vector\n",
    "q = np.random.randn(L,d_k)   # what i am lookling for\n",
    "k = np.random.randn(L,d_k)   # what i can offer\n",
    "v = np.random.randn(L,d_v)   # what i actually offer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q  [[ 0.13835544  0.05302069 -1.92056396 -0.41408459 -0.90817973  0.95487426\n",
      "   0.09066509 -0.83239626]\n",
      " [-0.58171481  1.02591346  0.12084231 -0.28284516 -0.31526041  1.02373095\n",
      "   0.3095154   0.60866634]\n",
      " [-0.83997612  0.17209111  0.58317121 -0.7895387   0.54820306  0.53428\n",
      "   0.39383483  0.95668413]\n",
      " [ 1.40365343 -0.14056982  0.20769021 -0.34202094 -0.91800571 -1.59050277\n",
      "  -0.76118562  0.26963971]] \n",
      "K  [[-0.60717842  0.69754786 -1.45232277  0.21975905 -0.31690028  0.02860548\n",
      "   0.80309597 -2.02521947]\n",
      " [-1.09924128  0.3204701  -0.93089215 -1.22689331 -2.48123274 -0.32521921\n",
      "  -0.12317847 -0.09667761]\n",
      " [-0.85188565 -0.09358945 -0.48384823  0.93090039  0.5680219   1.22635384\n",
      "  -0.54950555 -0.04131698]\n",
      " [-1.54796687  0.45822898 -0.72845734 -0.35873565  0.12729905  1.79042244\n",
      "  -1.06175841  1.29584968]] \n",
      "V  [[ 0.18039911 -0.75172325  0.25897613  0.86573161  0.64354282 -0.46825087\n",
      "  -1.53045598 -1.63294178]\n",
      " [-0.36924828 -0.8889616   0.25361375 -0.13002521 -0.67815793  0.1080676\n",
      "   0.59982142  0.84564174]\n",
      " [ 0.92587229 -1.53294639 -0.49048837  0.68421039  0.44977628  0.66156987\n",
      "   1.32968115 -1.0660807 ]\n",
      " [ 0.80444915  2.00603411 -1.11885402 -0.8246261   0.87315245 -2.29504141\n",
      "   0.62058808  1.02947091]]\n"
     ]
    }
   ],
   "source": [
    "print('Q ',q,'\\nK ',k,'\\nV ',v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.7249729 ,  4.17294896,  1.06068365,  1.77681484],\n",
       "       [-0.02375334,  1.55507663,  0.95892269,  3.63690472],\n",
       "       [-2.17005448, -0.27068267,  0.39297539,  3.08546666],\n",
       "       [-2.23908317,  1.50102523, -3.66630582, -4.07274586]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(q,k.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5906333774021342, 0.9100498619054902, 6.596802896569788)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #why we need sqrt(d_k) in denominator\n",
    "q.var(),k.var(), np.matmul(q,k.T).var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5906333774021342, 0.9100498619054902, 0.9375)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled = np.matmul(q,k.T)//math.sqrt(d_k)\n",
    "q.var(),k.var(), scaled.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  0.,  0.],\n",
       "       [-1.,  0.,  0.,  1.],\n",
       "       [-1., -1.,  0.,  1.],\n",
       "       [-1.,  0., -2., -2.]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.tril(np.ones((L,L)))\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., -inf, -inf, -inf],\n",
       "       [  0.,   0., -inf, -inf],\n",
       "       [  0.,   0.,   0., -inf],\n",
       "       [  0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[mask == 0] = -np.infty\n",
    "mask[mask == 1] = 0\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1., -inf, -inf, -inf],\n",
       "       [ -1.,   0., -inf, -inf],\n",
       "       [ -1.,  -1.,   0., -inf],\n",
       "       [ -1.,   0.,  -2.,  -2.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled + mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_extra(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "def softmax(x):\n",
    "    return (np.exp(x).T / np.sum(np.exp(x), axis = -1)).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.26894142, 0.73105858, 0.        , 0.        ],\n",
       "       [0.21194156, 0.21194156, 0.57611688, 0.        ],\n",
       "       [0.22451524, 0.61029569, 0.08259454, 0.08259454]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = softmax(scaled + mask)\n",
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.18039911, -0.75172325,  0.25897613,  0.86573161,  0.64354282,\n",
       "        -0.46825087, -1.53045598, -1.63294178],\n",
       "       [-0.22142533, -0.85205253,  0.25505592,  0.13777504, -0.32269785,\n",
       "        -0.04692831,  0.02690159,  0.17904796],\n",
       "       [ 0.49338567, -1.2308856 , -0.17393953,  0.55011192,  0.25178733,\n",
       "         0.30480377,  0.56881162, -0.78104869],\n",
       "       [-0.04193318, -0.67222829,  0.08000057,  0.10341854, -0.160125  ,\n",
       "        -0.17409209,  0.18353933,  0.14644743]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_v = np.matmul(attention,v)\n",
    "new_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.18039911, -0.75172325,  0.25897613,  0.86573161,  0.64354282,\n",
       "        -0.46825087, -1.53045598, -1.63294178],\n",
       "       [-0.36924828, -0.8889616 ,  0.25361375, -0.13002521, -0.67815793,\n",
       "         0.1080676 ,  0.59982142,  0.84564174],\n",
       "       [ 0.92587229, -1.53294639, -0.49048837,  0.68421039,  0.44977628,\n",
       "         0.66156987,  1.32968115, -1.0660807 ],\n",
       "       [ 0.80444915,  2.00603411, -1.11885402, -0.8246261 ,  0.87315245,\n",
       "        -2.29504141,  0.62058808,  1.02947091]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "L, d_k, d_v = 4, 8, 8   # L-> size of input and d_v and d_k is length of vector\n",
    "q = np.random.randn(L,d_k)   # what i am lookling for\n",
    "k = np.random.randn(L,d_k)   # what i can offer\n",
    "v = np.random.randn(L,d_v)   # what i actually offer\n",
    "def softmax(x):\n",
    "    return np.exp(x)/np.sum(np.exp(x), axis=0)\n",
    "\n",
    "def mask():\n",
    "    maskMat = np.tril(np.ones((L,L)))\n",
    "    maskMat[maskMat == 0] = -np.infty\n",
    "    maskMat[maskMat == 1] = 0\n",
    "    return maskMat\n",
    "\n",
    "def scaled_dot_product_attention(q,k,v, mask=None):\n",
    "    d_k = q.shape[-1]\n",
    "    scaled = np.matmul(q,k.T) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled =  scaled + mask()\n",
    "    \n",
    "    attention = softmax(scaled)\n",
    "\n",
    "    out = np.matmul(attention, v)\n",
    "    return out,attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "sequence_length = 4 # my name is ajay\n",
    "batch_size = 1 # helps in parrallel processing\n",
    "input_dim = 512 # vector input goes to attention \n",
    "d_model = 512 #  output of attention unit for every single words\n",
    "x = torch.randn(batch_size, sequence_length, input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method type of Tensor object at 0x12ec10640>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x.type)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "qkv_layer = nn.Linear(input_dim, 3*d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=1536, bias=True)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=5, out_features=1, bias=True)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## Creating an object for the linear class\n",
    "linear_layer = nn.Linear(in_features=5, out_features=1)\n",
    "linear_layer    \n",
    "\n",
    "# input = (*, in_feature)   \n",
    "# output = (*, out_feature)  \n",
    "# bias = out_feature\n",
    "# weight matrix = in_feature * out_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2., 3., 4.]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Passing input to the linear layer\n",
    "# x = (torch.arange(20),dtype = torch.float32).view(4,5)\n",
    "x = torch.arange((5),dtype = torch.float32).view(1,5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1490,  0.1820, -0.4206, -0.1481,  0.3122]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.3018], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(linear_layer.weight)\n",
    "print(linear_layer.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4471]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multihead attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "sequence_length = 4 # my name is ajay\n",
    "batch_size = 1 # helps in parrallel processing\n",
    "input_dim = 512 # vector input goes to attention    ### after positional encoding\n",
    "d_model = 512 #  output of attention unit for every single words\n",
    "x = torch.randn(batch_size, sequence_length, input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "qkv_layer = nn.Linear(input_dim, 3*d_model)    # for each q,k,v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 1536])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv = qkv_layer(x )\n",
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 8, 192])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums_heads = 8\n",
    "head_dim = d_model // nums_heads\n",
    "qkv = qkv.reshape(batch_size, sequence_length, nums_heads, 3*head_dim)  # 3 becuase it is combination of q,k,v vector\n",
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 192])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv = qkv.permute(0,2,1,3)\n",
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 4, 64]))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# breaking down qkv vector into individual by last dimention\n",
    "q,k,v = qkv.chunk(3, dim = -1)\n",
    "q.shape, k.shape, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_k = q.size()[-1]\n",
    "scaled = torch.matmul(q, k.transpose(-2,-1))/math.sqrt(d_k)\n",
    "scaled.shape    # basically our sequence length\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf],\n",
       "        [0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.full(scaled.size() , float('-inf'))\n",
    "mask = torch.triu(mask, diagonal=1)\n",
    "mask[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3939,    -inf,    -inf,    -inf],\n",
       "        [-0.1757, -0.2276,    -inf,    -inf],\n",
       "        [ 0.7108, -0.1185, -0.0219,    -inf],\n",
       "        [ 0.2490, -0.0359,  0.2940, -0.4631]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(scaled + mask)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled +=mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5130, 0.4870, 0.0000, 0.0000],\n",
       "        [0.5217, 0.2276, 0.2507, 0.0000],\n",
       "        [0.3041, 0.2287, 0.3181, 0.1492]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = F.softmax(scaled, dim=-1)\n",
    "attention[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 64])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = torch.matmul(attention, v)\n",
    "value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def scaled_dot_product(q, k, v, mask = None):\n",
    "    d_k = q.size()[-1]\n",
    "    scaled = torch.matmul(q, k.transpose(-2,-1)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled +=mask\n",
    "    \n",
    "    attention = F.softmax(scaled, dim = -1)\n",
    "    values = torch.matmul(attention, v)\n",
    "\n",
    "    return values, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 4, 64]), torch.Size([1, 8, 4, 4]))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values, attention = scaled_dot_product(q,k,v, mask = None)\n",
    "values.shape , attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3402, 0.1514, 0.2852, 0.2232],\n",
       "        [0.1685, 0.1600, 0.2717, 0.3998],\n",
       "        [0.3671, 0.1602, 0.1764, 0.2963],\n",
       "        [0.3041, 0.2287, 0.3181, 0.1492]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 4, 64]), torch.Size([1, 8, 4, 4]))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values, attention = scaled_dot_product(q,k,v, mask = mask)\n",
    "values.shape , attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5130, 0.4870, 0.0000, 0.0000],\n",
       "        [0.5217, 0.2276, 0.2507, 0.0000],\n",
       "        [0.3041, 0.2287, 0.3181, 0.1492]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = values.reshape(batch_size, sequence_length, nums_heads*head_dim)\n",
    "values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer = nn.Linear(d_model, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multihead dimention code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, nums_heads):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.d_model = d_model\n",
    "        self.nums_head = nums_heads\n",
    "        self.head_dim = d_model // nums_heads\n",
    "        self.qkv_layer = nn.Linear(input_dim, 3 * d_model)\n",
    "        self.linear_layer = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def scaled_dot_product(self, q, k, v, mask = None):\n",
    "        d_k = q.size()[-1]\n",
    "        scaled = torch.matmul(q, k.transpose(-2,-1)) / math.sqrt(d_k)\n",
    "        if mask is not None:\n",
    "            scaled +=mask\n",
    "        \n",
    "        attention = F.softmax(scaled, dim = -1)\n",
    "        values = torch.matmul(attention, v)\n",
    "        return values, attention\n",
    "    def forward(self, x, mask=None):\n",
    "        batch_size, sequence_length, input_dim = x.size()\n",
    "        qkv = self.qkv_layer(x)\n",
    "        print(\"qkv shape: \", qkv.shape)\n",
    "        qkv = qkv.reshape(batch_size, sequence_length, self.nums_head, 3 * self.head_dim)\n",
    "        print(\"qkv shape: \", qkv.shape)\n",
    "        qkv = qkv.permute(0,2,1,3)\n",
    "        print(\"qkv shape: \", qkv.shape)\n",
    "        q, k, v = qkv.chunk(3, dim = -1)\n",
    "        print(\"q: \",q.shape, '\\nk: ',k.shape, '\\nv: ',v.shape)\n",
    "        values, attention = self.scaled_dot_product(q,k,v, mask)\n",
    "        print(\"values shape : \",values.shape)\n",
    "        print(\"Attention shape : \",attention.shape)\n",
    "        values = values.reshape(batch_size, sequence_length, self.nums_head * self.head_dim)\n",
    "        print(\"values shape : \",values.shape)\n",
    "        out = self.linear_layer(values)\n",
    "        print(\"output shape : \",out.shape)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qkv shape:  torch.Size([1, 4, 1536])\n",
      "qkv shape:  torch.Size([1, 4, 8, 192])\n",
      "qkv shape:  torch.Size([1, 8, 4, 192])\n",
      "q:  torch.Size([1, 8, 4, 64]) \n",
      "k:  torch.Size([1, 8, 4, 64]) \n",
      "v:  torch.Size([1, 8, 4, 64])\n",
      "values shape :  torch.Size([1, 8, 4, 64])\n",
      "Attention shape :  torch.Size([1, 8, 4, 4])\n",
      "values shape :  torch.Size([1, 4, 512])\n",
      "output shape :  torch.Size([1, 4, 512])\n"
     ]
    }
   ],
   "source": [
    "input_dim = 512\n",
    "d_model =  512\n",
    "nums_head = 8\n",
    "batch_size = 1\n",
    "sequence_length = 4\n",
    "x = torch.randn(batch_size, sequence_length, input_dim)\n",
    "\n",
    "model = MultiheadAttention(input_dim, d_model, nums_head)\n",
    "put = model.forward(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = 4  # my seq length is 4 but defininng\n",
    "d_model = 6         # actually 512 but for illustration purpose 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4.])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_i = torch.arange(0,d_model,2).float()\n",
    "even_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1.0000,  21.5443, 464.1590])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_denominator = torch.pow(10000,even_i / d_model)\n",
    "even_denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 3., 5.])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_i = torch.arange(1,d_model,2).float()\n",
    "odd_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1.0000,  21.5443, 464.1590])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_denominator = torch.pow(10000,(odd_i -1 )/ d_model)\n",
    "odd_denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1.0000,  21.5443, 464.1590])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we are using single denominator becoz odd and even both are same\n",
    "denominator = torch.pow(10000,(odd_i -1 )/ d_model)   \n",
    "denominator   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0000, 0.0928, 0.0086]), tensor([1.0000, 0.1392, 0.0108]))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_i / denominator , odd_i / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [1.],\n",
       "        [2.],\n",
       "        [3.]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position = torch.arange(max_sequence_length,dtype=torch.float).reshape(max_sequence_length,1)\n",
    "position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [1.0000e+00, 4.6416e-02, 2.1544e-03],\n",
       "         [2.0000e+00, 9.2832e-02, 4.3089e-03],\n",
       "         [3.0000e+00, 1.3925e-01, 6.4633e-03]]),\n",
       " tensor([  1.0000,  21.5443, 464.1590]))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position/denominator , denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000, 0.0000, 0.0000],\n",
       "         [0.8415, 0.0464, 0.0022],\n",
       "         [0.9093, 0.0927, 0.0043],\n",
       "         [0.1411, 0.1388, 0.0065]]),\n",
       " tensor([[ 1.0000,  1.0000,  1.0000],\n",
       "         [ 0.5403,  0.9989,  1.0000],\n",
       "         [-0.4161,  0.9957,  1.0000],\n",
       "         [-0.9900,  0.9903,  1.0000]]))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_PE = torch.sin(position/denominator)\n",
    "odd_PE = torch.cos(position/denominator)\n",
    "\n",
    "even_PE , odd_PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  1.0000],\n",
       "         [ 0.0000,  1.0000],\n",
       "         [ 0.0000,  1.0000]],\n",
       "\n",
       "        [[ 0.8415,  0.5403],\n",
       "         [ 0.0464,  0.9989],\n",
       "         [ 0.0022,  1.0000]],\n",
       "\n",
       "        [[ 0.9093, -0.4161],\n",
       "         [ 0.0927,  0.9957],\n",
       "         [ 0.0043,  1.0000]],\n",
       "\n",
       "        [[ 0.1411, -0.9900],\n",
       "         [ 0.1388,  0.9903],\n",
       "         [ 0.0065,  1.0000]]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joining both even_PE and odd_PE\n",
    "stacked = torch.stack([even_PE, odd_PE], dim =2)\n",
    "stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  1.0000],\n",
       "        [ 0.8415,  0.5403,  0.0464,  0.9989,  0.0022,  1.0000],\n",
       "        [ 0.9093, -0.4161,  0.0927,  0.9957,  0.0043,  1.0000],\n",
       "        [ 0.1411, -0.9900,  0.1388,  0.9903,  0.0065,  1.0000]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#falten this\n",
    "PE = torch.flatten(stacked, start_dim=1, end_dim=2)\n",
    "PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_sequence_length):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "    \n",
    "    def forward(self):\n",
    "        even_i = torch.arange(0,self.d_model,2).float()\n",
    "        odd_i = torch.arange(1,self.d_model,2).float()\n",
    "        denominator = torch.pow(10000,(odd_i -1 )/ d_model)   \n",
    "        position = torch.arange(self.max_sequence_length).reshape(self.max_sequence_length,1)\n",
    "        even_PE = torch.sin(position / denominator)\n",
    "        odd_PE = torch.cos(position / denominator)\n",
    "\n",
    "        stacked = torch.stack([even_PE,odd_PE],dim = 2)\n",
    "        PE = torch.flatten(stacked , start_dim=1, end_dim=2)\n",
    "        return PE\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  1.0000],\n",
       "        [ 0.8415,  0.5403,  0.0464,  0.9989,  0.0022,  1.0000],\n",
       "        [ 0.9093, -0.4161,  0.0927,  0.9957,  0.0043,  1.0000],\n",
       "        [ 0.1411, -0.9900,  0.1388,  0.9903,  0.0065,  1.0000]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PositionalEncoding(6,4)\n",
    "PE = model.forward()\n",
    "PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 3])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.Tensor([[[0.2, 0.1, 0.3], [0.5, 0.1, 0.1]]])\n",
    "B, S, E = inputs.size()\n",
    "inputs = inputs.reshape(S, B, E)\n",
    "inputs.size()   # number of words, batch size , embedding of each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[1., 1., 1.]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0., 0., 0.]], requires_grad=True))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_shape = inputs.size()[-2:]\n",
    "gamma = nn.Parameter(torch.ones(parameter_shape))\n",
    "beta = nn.Parameter(torch.zeros(parameter_shape))\n",
    "print(parameter_shape)\n",
    "gamma,beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, -2]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims = [-(i + 1)for i in range(len(parameter_shape))]\n",
    "dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.2000]],\n",
       " \n",
       "         [[0.2333]]]),\n",
       " torch.Size([2, 1, 1]))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = inputs.mean(dim = dims, keepdim = True)\n",
    "mean, mean.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0817]],\n",
       "\n",
       "        [[0.1886]]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = ((inputs - mean) ** 2).mean(dim = dims, keepdim = True)\n",
    "epsilon = 1e-5\n",
    "std = (var + epsilon).sqrt()\n",
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000, -1.2238,  1.2238]],\n",
       "\n",
       "        [[ 1.4140, -0.7070, -0.7070]]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = (inputs-mean)/std\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000, -1.2238,  1.2238]],\n",
       "\n",
       "        [[ 1.4140, -0.7070, -0.7070]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = gamma * y + beta\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn\n",
    "class LayerNormalization():\n",
    "    def __init__(self, parameter_shape, eps = 1e-5):\n",
    "        self.parameter_shape = parameter_shape\n",
    "        self.eps = eps\n",
    "        self.gamma = nn.Parameter(torch.ones(parameter_shape))\n",
    "        self.beta = nn.Parameter(torch.zeros(parameter_shape))\n",
    "\n",
    "    def forward(self, input):\n",
    "        dims = [-(i+1) for i in range(len(self.parameter_shape))]\n",
    "        mean = inputs.mean(dim = dims, keepdim = True)\n",
    "        print(\"Mean : \",mean.size(),mean)\n",
    "        var = ((inputs-mean)**2).mean(dim = dims, keepdim = True)\n",
    "        std = (var + self.eps).sqrt()\n",
    "        print(\"STD: \",std.shape, std)\n",
    "        y = (input - mean) / std\n",
    "\n",
    "        print(\"y: \",y.shape,y)\n",
    "\n",
    "        out = self.gamma * y + self.beta\n",
    "        print(\"out: \",out.shape, out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 3, 8]),\n",
       " tensor([[ 0.5466,  1.9774, -0.2422,  1.8863,  1.4273, -0.2646,  1.5859,  2.1209],\n",
       "         [-0.7454, -0.8438,  2.9146, -0.0053,  1.1575, -1.2436,  0.1926,  0.3608],\n",
       "         [ 1.7229, -0.1413, -1.9222, -1.0064, -1.2585, -1.3769,  2.0752,  2.1619]]))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 3\n",
    "sentence_length = 5\n",
    "embedding_dim = 8\n",
    "inputs = torch.randn(sentence_length, batch_size, embedding_dim)\n",
    "inputs.size(), inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean :  torch.Size([5, 3, 1]) tensor([[[ 1.1297],\n",
      "         [ 0.2234],\n",
      "         [ 0.0318]],\n",
      "\n",
      "        [[-0.5829],\n",
      "         [-0.0419],\n",
      "         [ 0.0219]],\n",
      "\n",
      "        [[-0.2787],\n",
      "         [-0.0486],\n",
      "         [-0.0353]],\n",
      "\n",
      "        [[ 0.2828],\n",
      "         [ 0.8355],\n",
      "         [ 0.1275]],\n",
      "\n",
      "        [[ 0.3711],\n",
      "         [-0.0401],\n",
      "         [ 0.0690]]])\n",
      "STD:  torch.Size([5, 3, 1]) tensor([[[0.9176],\n",
      "         [1.2458],\n",
      "         [1.5870]],\n",
      "\n",
      "        [[1.2928],\n",
      "         [1.1881],\n",
      "         [0.5851]],\n",
      "\n",
      "        [[0.8185],\n",
      "         [0.6662],\n",
      "         [1.1070]],\n",
      "\n",
      "        [[1.2932],\n",
      "         [0.6500],\n",
      "         [0.9273]],\n",
      "\n",
      "        [[0.7234],\n",
      "         [1.1516],\n",
      "         [1.1884]]])\n",
      "y:  torch.Size([5, 3, 8]) tensor([[[-0.6354,  0.9237, -1.4951,  0.8245,  0.3243, -1.5194,  0.4972,\n",
      "           1.0801],\n",
      "         [-0.7776, -0.8566,  2.1602, -0.1836,  0.7497, -1.1775, -0.0248,\n",
      "           0.1103],\n",
      "         [ 1.0656, -0.1091, -1.2313, -0.6542, -0.8131, -0.8877,  1.2876,\n",
      "           1.3422]],\n",
      "\n",
      "        [[-2.0630,  1.0763,  0.4591, -0.7358,  1.1814,  0.0080,  0.5033,\n",
      "          -0.4292],\n",
      "         [-0.7382, -1.1701, -0.3038,  1.1174,  1.0038,  1.1022,  0.4972,\n",
      "          -1.5084],\n",
      "         [ 0.7178,  0.7124,  1.1905, -0.3916, -1.3534, -1.7789,  0.4181,\n",
      "           0.4852]],\n",
      "\n",
      "        [[-1.3260, -0.4467, -0.2663, -1.0218,  1.2843,  0.3178,  1.7572,\n",
      "          -0.2984],\n",
      "         [-0.1147,  0.7348, -2.0097,  0.0389,  1.2784, -0.0155,  0.9841,\n",
      "          -0.8963],\n",
      "         [ 0.8493,  0.6147,  0.2246,  1.4817, -1.5597, -0.2348,  0.0932,\n",
      "          -1.4691]],\n",
      "\n",
      "        [[-1.3949,  1.7585, -0.4712,  0.4950, -0.8397,  0.0908,  1.1071,\n",
      "          -0.7455],\n",
      "         [-0.8837,  1.5020, -0.2431,  0.1959,  1.5529, -0.0658, -1.4364,\n",
      "          -0.6217],\n",
      "         [-0.3397,  0.5073,  0.2318,  1.1372, -0.7577,  1.5748, -0.6994,\n",
      "          -1.6543]],\n",
      "\n",
      "        [[ 1.0432,  1.3276, -1.0836, -1.6869,  0.6855,  0.4989, -0.1662,\n",
      "          -0.6185],\n",
      "         [-1.0017, -0.1806,  1.5946,  0.0391,  1.1698,  0.0801, -1.7444,\n",
      "           0.0430],\n",
      "         [-1.0218,  2.1191,  0.3391, -0.3474, -0.4375, -1.0908,  0.8328,\n",
      "          -0.3935]]])\n",
      "out:  torch.Size([5, 3, 8]) tensor([[[-0.6354,  0.9237, -1.4951,  0.8245,  0.3243, -1.5194,  0.4972,\n",
      "           1.0801],\n",
      "         [-0.7776, -0.8566,  2.1602, -0.1836,  0.7497, -1.1775, -0.0248,\n",
      "           0.1103],\n",
      "         [ 1.0656, -0.1091, -1.2313, -0.6542, -0.8131, -0.8877,  1.2876,\n",
      "           1.3422]],\n",
      "\n",
      "        [[-2.0630,  1.0763,  0.4591, -0.7358,  1.1814,  0.0080,  0.5033,\n",
      "          -0.4292],\n",
      "         [-0.7382, -1.1701, -0.3038,  1.1174,  1.0038,  1.1022,  0.4972,\n",
      "          -1.5084],\n",
      "         [ 0.7178,  0.7124,  1.1905, -0.3916, -1.3534, -1.7789,  0.4181,\n",
      "           0.4852]],\n",
      "\n",
      "        [[-1.3260, -0.4467, -0.2663, -1.0218,  1.2843,  0.3178,  1.7572,\n",
      "          -0.2984],\n",
      "         [-0.1147,  0.7348, -2.0097,  0.0389,  1.2784, -0.0155,  0.9841,\n",
      "          -0.8963],\n",
      "         [ 0.8493,  0.6147,  0.2246,  1.4817, -1.5597, -0.2348,  0.0932,\n",
      "          -1.4691]],\n",
      "\n",
      "        [[-1.3949,  1.7585, -0.4712,  0.4950, -0.8397,  0.0908,  1.1071,\n",
      "          -0.7455],\n",
      "         [-0.8837,  1.5020, -0.2431,  0.1959,  1.5529, -0.0658, -1.4364,\n",
      "          -0.6217],\n",
      "         [-0.3397,  0.5073,  0.2318,  1.1372, -0.7577,  1.5748, -0.6994,\n",
      "          -1.6543]],\n",
      "\n",
      "        [[ 1.0432,  1.3276, -1.0836, -1.6869,  0.6855,  0.4989, -0.1662,\n",
      "          -0.6185],\n",
      "         [-1.0017, -0.1806,  1.5946,  0.0391,  1.1698,  0.0801, -1.7444,\n",
      "           0.0430],\n",
      "         [-1.0218,  2.1191,  0.3391, -0.3474, -0.4375, -1.0908,  0.8328,\n",
      "          -0.3935]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer_norm = LayerNormalization(inputs.size()[-1:])\n",
    "out = layer_norm.forward(inputs)\n",
    "# out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 3, 1])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Sample data (categorical labels)\n",
    "labels = torch.tensor([1, 0, 3, 1])  # Example labels (categories)\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_categories = labels.max() + 1\n",
    "num_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 1, 0, 0]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = torch.nn.functional.one_hot(labels, num_classes=num_categories)\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
