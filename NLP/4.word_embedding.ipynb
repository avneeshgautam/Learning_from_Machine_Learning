{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/data2/home/avneeshg/.local/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so: undefined symbol: ncclCommRegister",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/__init__.py:290\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m USE_GLOBAL_DEPS:\n\u001b[1;32m    289\u001b[0m         _load_global_deps()\n\u001b[0;32m--> 290\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;66;03m# Appease the type checker; ordinarily this binding is inserted by the\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;66;03m# torch._C module initialization code in C\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "\u001b[0;31mImportError\u001b[0m: /data2/home/avneeshg/.local/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so: undefined symbol: ncclCommRegister"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'the glass of milk',\n",
    "    'the glass of juice',\n",
    "    'the cup of tea',\n",
    "    'I am a good boy',\n",
    "    'I am a good developer',\n",
    "    'understand the meaning of words',\n",
    "    'your videos are good'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'good': 1,\n",
       " 'words': 2,\n",
       " 'glass': 3,\n",
       " 'the': 4,\n",
       " 'boy': 5,\n",
       " 'tea': 6,\n",
       " 'developer': 7,\n",
       " 'juice': 8,\n",
       " 'am': 9,\n",
       " 'are': 10,\n",
       " 'milk': 11,\n",
       " 'of': 12,\n",
       " 'videos': 13,\n",
       " 'cup': 14,\n",
       " 'understand': 15,\n",
       " 'a': 16,\n",
       " 'I': 17,\n",
       " 'meaning': 18,\n",
       " 'your': 19}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Step 1: Create a vocabulary and word-to-index mapping\n",
    "vocab = set(word for sentence in sentences for word in sentence.split())\n",
    "vocab_size = len(vocab)\n",
    "word_to_idx = {word: i+1 for i, word in enumerate(vocab)}  # Index starts from 1 for padding\n",
    "word_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4, 3, 12, 11],\n",
       " [4, 3, 12, 8],\n",
       " [4, 14, 12, 6],\n",
       " [17, 9, 16, 1, 5],\n",
       " [17, 9, 16, 1, 7],\n",
       " [15, 4, 18, 12, 2],\n",
       " [19, 13, 10, 1]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Step 2: One-hot encoding (using indices instead of actual one-hot vectors)\n",
    "encoded_sentences = [[word_to_idx[word] for word in sentence.split()] for sentence in sentences]\n",
    "encoded_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Step 3: Padding sequences to ensure same length\u001b[39;00m\n\u001b[1;32m      2\u001b[0m sent_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m----> 3\u001b[0m padded_sentences \u001b[38;5;241m=\u001b[39m [F\u001b[38;5;241m.\u001b[39mpad(torch\u001b[38;5;241m.\u001b[39mtensor(sentence), (sent_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(sentence), \u001b[38;5;241m0\u001b[39m), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m encoded_sentences]\n",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Step 3: Padding sequences to ensure same length\u001b[39;00m\n\u001b[1;32m      2\u001b[0m sent_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m----> 3\u001b[0m padded_sentences \u001b[38;5;241m=\u001b[39m [\u001b[43mF\u001b[49m\u001b[38;5;241m.\u001b[39mpad(torch\u001b[38;5;241m.\u001b[39mtensor(sentence), (sent_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(sentence), \u001b[38;5;241m0\u001b[39m), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m encoded_sentences]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 3: Padding sequences to ensure same length\n",
    "sent_length = 8\n",
    "padded_sentences = [F.pad(torch.tensor(sentence), (sent_length - len(sentence), 0), value=0) for sentence in encoded_sentences]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensor\n",
    "padded_sentences = torch.stack(padded_sentences)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the padded sequences\n",
    "print(\"Padded Sentences:\\n\", padded_sentences)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define an embedding layer and pass the padded sentences through it\n",
    "embedding_dim = 10\n",
    "embedding_layer = nn.Embedding(vocab_size + 1, embedding_dim, padding_idx=0)  # +1 for padding index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings\n",
    "embedded_sentences = embedding_layer(padded_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print the embedded representations\n",
    "print(\"Embedded Sentences:\\n\", embedded_sentences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
